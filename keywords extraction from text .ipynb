{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =ur link here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of keywords to be extracted; initialised to 10\n",
    "number_of_keywords = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS TO CREATE YOUR CORPUS FROM .TXT FILES\n",
    "def extract_corpus():\n",
    "    corpus = []\n",
    "    for file in glob.glob(os.path.join(path, '*.txt')):\n",
    "        f = open(file, 'r', encoding='latin-1')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "\n",
    "        # formatting text for pretty print\n",
    "        text = text.replace('.', ' ')\n",
    "        text = re.sub(r'\\s+', ' ', re.sub(r'[^\\w \\s]', '', text)).lower()\n",
    "        corpus.append(text)\n",
    "\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF_IDF MODULE; RETURNS KEYWORDS FOR EACH DOCUMENT\n",
    "def tf_idf(corpus):\n",
    "    # initializing vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(corpus)\n",
    "    names = vectorizer.get_feature_names()\n",
    "    data = vectors.todense().tolist()\n",
    "\n",
    "    # Create a dataframe with the results\n",
    "    df = pd.DataFrame(data, columns=names)\n",
    "\n",
    "    # filtering stopwords\n",
    "    st = set(stopwords.words('english'))\n",
    "    df = df[filter(lambda x: x not in list(st), df.columns)]\n",
    "\n",
    "    # printing top 10 keywords\n",
    "    N = number_of_keywords\n",
    "    for i in df.iterrows():\n",
    "        print(i[1].sort_values(ascending=False)[:N])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    corpus = extract_corpus()\n",
    "    tf_idf(corpus)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF/IDF can be fast and effective; But RAKE is more intuitive for phrases longer than a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Method 2 using Rake # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from rake_nltk import Rake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = your link here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAKE MODULE; RETURNS KEYWORDS FOR EACH DOCUMENT\n",
    "def rake():\n",
    "    # exhaustive list of stop words\n",
    "    stop_dir = \"Stoplist\"\n",
    "\n",
    "    # initializing rake module\n",
    "    # min_length = minimum number of words in keyword phrases\n",
    "    # max_length = maximum number of words in keyword phrases\n",
    "    # adjust min_length and max_length to your preference\n",
    "    r = Rake(stopwords=stop_dir, min_length=1, max_length=4)\n",
    "\n",
    "    # reading from file\n",
    "    for file in glob.glob(os.path.join(path, '*.txt')):\n",
    "        f = open(file, 'r', encoding='latin-1')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "\n",
    "        # formatting text for pretty print\n",
    "        text = text.replace('.', ' ')\n",
    "        text = re.sub(r'\\s+', ' ', re.sub(r'[^\\w \\s]', '', text)).lower()\n",
    "\n",
    "        # extracting keywords\n",
    "        r.extract_keywords_from_text(text)\n",
    "\n",
    "        # printing ranked phrases\n",
    "        ranked_phrases = r.get_ranked_phrases()\n",
    "        print(ranked_phrases)\n",
    "\n",
    "# calling rake module\n",
    "rake()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
